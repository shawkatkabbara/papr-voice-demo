<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PAPR Voice</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: #131417;
            color: white;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 600px;
            width: 100%;
            margin: 0 auto;
            text-align: center;
        }

        .logo-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            margin-bottom: 60px;
        }

        .logo {
            width: 120px;
            height: 120px;
        }

        .wordmark {
            font-size: 96px;
            font-weight: 500;
            color: white;
            letter-spacing: -0.02em;
            font-family: -apple-system, BlinkMacSystemFont, 'Inter', 'SF Pro Display', 'Segoe UI', sans-serif;
            text-transform: lowercase;
            line-height: 1;
            transform: translateY(0);
        }

        h1 {
            font-size: 24px;
            margin-bottom: 30px;
            color: rgba(255, 255, 255, 0.9);
            font-weight: 500;
        }

        #status {
            font-size: 24px;
            margin: 30px 0;
            min-height: 30px;
            transition: all 0.3s ease;
        }

        #status.idle { color: #0161E0; }
        #status.listening { color: #00FEFE; }
        #status.thinking { color: #0CCDFF; }
        #status.speaking { color: #0161E0; }

        .input-container {
            display: flex;
            align-items: center;
            background: rgba(255, 255, 255, 0.08);
            border-radius: 30px;
            padding: 12px 20px;
            margin: 30px auto;
            max-width: 500px;
            width: 100%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
        }

        .audio-button {
            background: linear-gradient(135deg, #0161E0, #0CCDFF);
            border: none;
            color: white;
            width: 44px;
            height: 44px;
            border-radius: 50%;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(1, 97, 224, 0.4);
            flex-shrink: 0;
        }

        .audio-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(0, 254, 254, 0.6);
        }

        .audio-button.active {
            background: #00FEFE;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        input[type="text"] {
            flex: 1;
            background: transparent;
            border: none;
            color: white;
            font-size: 16px;
            outline: none;
        }

        input[type="text"]::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        #transcript {
            margin-top: 40px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
        }

        #transcript.hidden {
            display: none;
        }

        .message {
            margin: 15px 0;
            padding: 10px;
            border-radius: 8px;
        }

        .user {
            background: rgba(1, 97, 224, 0.2);
            border-left: 3px solid #0161E0;
        }

        .assistant {
            background: rgba(0, 254, 254, 0.1);
            border-left: 3px solid #00FEFE;
        }

        .error {
            color: #ff4444;
            margin-top: 20px;
        }

        .info {
            color: #0CCDFF;
            font-size: 14px;
            margin-top: 30px;
        }

        /* Search Constellation Canvas */
        #constellation-canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
            pointer-events: auto;
        }

        .container {
            position: relative;
            z-index: 1;
            pointer-events: none; /* Allow clicks to pass through to canvas */
        }

        .container > * {
            pointer-events: auto; /* Re-enable clicks for UI elements */
        }

        /* Search Detail Modal */
        .search-modal {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(30, 30, 35, 0.98);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 16px;
            padding: 32px;
            width: 700px;
            max-width: 90%;
            max-height: 85vh;
            overflow-y: auto;
            z-index: 1000;
            backdrop-filter: blur(20px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
        }

        .search-modal.active {
            display: block;
        }

        .modal-header {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.6);
            margin-bottom: 8px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .modal-query {
            font-size: 18px;
            font-weight: 500;
            margin-bottom: 16px;
            color: white;
            font-style: italic;
            padding: 12px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
            border-left: 3px solid #00FEFE;
        }

        .modal-latency {
            font-size: 24px;
            color: #00FEFE;
            margin-bottom: 24px;
            font-weight: 600;
        }

        .modal-memories {
            margin-top: 16px;
        }

        .modal-memory-item {
            padding: 16px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
            margin-bottom: 12px;
            border-left: 3px solid rgba(255, 255, 255, 0.2);
        }

        .modal-memory-item:hover {
            background: rgba(255, 255, 255, 0.08);
        }

        .memory-score {
            color: #0CCDFF;
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 4px;
        }

        .memory-content {
            color: rgba(255, 255, 255, 0.9);
            font-size: 14px;
            line-height: 1.6;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }

        .memory-content em {
            color: rgba(255, 255, 255, 0.5);
            font-style: italic;
        }

        .memory-content.truncated {
            max-height: 150px;
            overflow: hidden;
            position: relative;
        }

        .memory-content.truncated::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 50px;
            background: linear-gradient(transparent, rgba(30, 30, 35, 0.98));
        }

        .show-more-btn {
            margin-top: 8px;
            padding: 6px 12px;
            background: rgba(12, 205, 255, 0.15);
            border: 1px solid rgba(12, 205, 255, 0.3);
            color: #0CCDFF;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            font-weight: 600;
            transition: all 0.2s ease;
        }

        .show-more-btn:hover {
            background: rgba(12, 205, 255, 0.25);
            border-color: #0CCDFF;
        }

        .memory-tags {
            margin-top: 8px;
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .tag {
            display: inline-block;
            padding: 3px 10px;
            background: rgba(255, 180, 0, 0.2);
            color: #FFB400;
            border-radius: 12px;
            font-size: 11px;
            font-weight: 600;
            border: 1px solid rgba(255, 180, 0, 0.3);
        }

        .topic {
            display: inline-block;
            padding: 3px 10px;
            background: rgba(0, 166, 153, 0.2);
            color: #00A699;
            border-radius: 12px;
            font-size: 11px;
            font-weight: 600;
            border: 1px solid rgba(0, 166, 153, 0.3);
        }

        .metadata-section {
            margin-top: 8px;
            padding: 8px;
            background: rgba(255, 255, 255, 0.03);
            border-radius: 6px;
            font-size: 11px;
            color: #767676;
        }

        .latency-breakdown {
            margin-top: 8px;
            padding: 12px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
            font-size: 13px;
        }

        .latency-item {
            display: flex;
            justify-content: space-between;
            padding: 4px 0;
            color: rgba(255, 255, 255, 0.8);
        }

        .latency-item .label {
            color: rgba(255, 255, 255, 0.6);
        }

        .latency-item .value {
            color: #0CCDFF;
            font-weight: 600;
        }

        .modal-close {
            position: absolute;
            top: 16px;
            right: 16px;
            background: none;
            border: none;
            color: rgba(255, 255, 255, 0.6);
            font-size: 24px;
            cursor: pointer;
            padding: 4px 8px;
            line-height: 1;
        }

        .modal-close:hover {
            color: white;
        }

        .modal-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: 999;
        }

        .modal-overlay.active {
            display: block;
        }
    </style>
</head>
<body>
    <canvas id="constellation-canvas"></canvas>

    <div class="modal-overlay" id="modalOverlay"></div>

    <div class="search-modal" id="searchModal">
        <button class="modal-close" id="modalClose">&times;</button>
        <div class="modal-header">Search Query</div>
        <div class="modal-query" id="modalQuery"></div>
        <div class="modal-latency" id="modalLatency"></div>
        <div id="modalLatencyBreakdown"></div>
        <div class="modal-header">Top Memories</div>
        <div class="modal-memories" id="modalMemories"></div>
    </div>

    <div class="container">
        <div class="logo-container">
            <img src="/logo.svg" alt="PAPR" class="logo">
            <div class="wordmark">PAPR</div>
        </div>

        <div class="input-container">
            <button id="audioBtn" class="audio-button">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M12 15C13.66 15 15 13.66 15 12V6C15 4.34 13.66 3 12 3C10.34 3 9 4.34 9 6V12C9 13.66 10.34 15 12 15Z" fill="white"/>
                    <path d="M17 12C17 14.76 14.76 17 12 17C9.24 17 7 14.76 7 12H5C5 15.53 7.61 18.43 11 18.92V21H13V18.92C16.39 18.43 19 15.53 19 12H17Z" fill="white"/>
                </svg>
            </button>
            <input type="text" id="textInput" placeholder="Ask about your memories...">
        </div>

        <div id="status" class="idle">Ready</div>

        <div id="transcript" class="hidden"></div>

        <div id="error" class="error"></div>
    </div>

    <script>
        // Configuration
        const PAPR_MEMORY_URL = '/api/search';  // ON-DEVICE CoreML search! (relative URL works with ngrok!)
        let WS_URL = null;  // Will be set dynamically with model from .env

        // State
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let isConnected = false;
        let OPENAI_API_KEY = null;
        let PAPR_API_KEY = null;
        let OPENAI_REALTIME_MODEL = null;
        let nextAudioTime = 0;

        // ========== SEARCH CONSTELLATION SYSTEM ==========
        const AIRBNB_COLORS = ['#FF5A5F', '#00A699', '#FC642D', '#484848', '#767676', '#FFB400'];
        const MAX_PARTICLES = 30;

        class Particle {
            constructor(x, y, color, searchData) {
                this.x = x;
                this.y = y;
                this.baseX = x;
                this.baseY = y;
                this.color = color;
                this.searchData = searchData;
                this.size = Math.max(8, Math.min(16, searchData.memories.length / 2)); // Larger particles
                this.opacity = 0;
                this.targetOpacity = 0.9;
                this.vx = (Math.random() - 0.5) * 0.3;
                this.vy = (Math.random() - 0.5) * 0.3;
                this.age = 0;
                this.hovering = false;
                this.glowIntensity = 0;
            }

            update() {
                // Gentle drift
                this.x += this.vx;
                this.y += this.vy;

                // Subtle return to base position
                this.x += (this.baseX - this.x) * 0.02;
                this.y += (this.baseY - this.y) * 0.02;

                // Fade in
                if (this.opacity < this.targetOpacity) {
                    this.opacity += 0.05;
                }

                // Animate glow on hover
                if (this.hovering) {
                    this.glowIntensity = Math.min(1, this.glowIntensity + 0.1);
                } else {
                    this.glowIntensity = Math.max(0, this.glowIntensity - 0.1);
                }

                this.age++;
            }

            draw(ctx) {
                ctx.save();
                ctx.globalAlpha = this.opacity;

                // Hover glow (extra strong when hovering)
                if (this.glowIntensity > 0) {
                    const hoverGradient = ctx.createRadialGradient(this.x, this.y, 0, this.x, this.y, this.size * 4);
                    hoverGradient.addColorStop(0, this.color);
                    hoverGradient.addColorStop(0.5, this.color);
                    hoverGradient.addColorStop(1, 'transparent');
                    ctx.globalAlpha = this.opacity * this.glowIntensity * 0.6;
                    ctx.fillStyle = hoverGradient;
                    ctx.fillRect(this.x - this.size * 4, this.y - this.size * 4, this.size * 8, this.size * 8);
                    ctx.globalAlpha = this.opacity;
                }

                // Outer glow
                const gradient = ctx.createRadialGradient(this.x, this.y, 0, this.x, this.y, this.size * 2);
                gradient.addColorStop(0, this.color);
                gradient.addColorStop(1, 'transparent');
                ctx.fillStyle = gradient;
                ctx.fillRect(this.x - this.size * 2, this.y - this.size * 2, this.size * 4, this.size * 4);

                // Core particle (slightly larger on hover)
                const coreSize = this.size * (1 + this.glowIntensity * 0.3);
                ctx.fillStyle = this.color;
                ctx.beginPath();
                ctx.arc(this.x, this.y, coreSize, 0, Math.PI * 2);
                ctx.fill();

                ctx.restore();
            }

            contains(x, y) {
                const dx = x - this.x;
                const dy = y - this.y;
                return Math.sqrt(dx * dx + dy * dy) < this.size * 3; // Larger click area
            }
        }

        class Constellation {
            constructor(canvasId) {
                this.canvas = document.getElementById(canvasId);
                this.ctx = this.canvas.getContext('2d');
                this.particles = [];
                this.mouseX = 0;
                this.mouseY = 0;
                this.resize();
                window.addEventListener('resize', () => this.resize());
                this.canvas.addEventListener('click', (e) => this.handleClick(e));
                this.canvas.addEventListener('mousemove', (e) => this.handleMouseMove(e));
                this.animate();
            }

            resize() {
                this.canvas.width = window.innerWidth;
                this.canvas.height = window.innerHeight;
                this.centerX = this.canvas.width / 2;
                this.centerY = this.canvas.height / 2;
            }

            addSearch(query, latencyMs, memories, latencyBreakdown) {
                // Remove oldest if at limit
                if (this.particles.length >= MAX_PARTICLES) {
                    this.particles.shift();
                }

                // Random position around center (further out to avoid UI overlap)
                const angle = Math.random() * Math.PI * 2;
                const distance = 250 + Math.random() * 250; // 250-500px from center
                const x = this.centerX + Math.cos(angle) * distance;
                const y = this.centerY + Math.sin(angle) * distance;

                // Random Airbnb color
                const color = AIRBNB_COLORS[Math.floor(Math.random() * AIRBNB_COLORS.length)];

                const searchData = {
                    query,
                    latencyMs,
                    memories: memories.slice(0, 30), // Top 30 memories
                    latencyBreakdown,
                    timestamp: new Date()
                };

                this.particles.push(new Particle(x, y, color, searchData));
            }

            handleMouseMove(e) {
                const rect = this.canvas.getBoundingClientRect();
                this.mouseX = e.clientX - rect.left;
                this.mouseY = e.clientY - rect.top;

                // Update hover state for all particles
                let anyHovering = false;
                for (let i = this.particles.length - 1; i >= 0; i--) {
                    if (this.particles[i].contains(this.mouseX, this.mouseY)) {
                        this.particles[i].hovering = true;
                        anyHovering = true;
                    } else {
                        this.particles[i].hovering = false;
                    }
                }

                // Change cursor if hovering over any particle
                this.canvas.style.cursor = anyHovering ? 'pointer' : 'default';
            }

            handleClick(e) {
                const rect = this.canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;

                // Check if clicked on a particle (reverse order to get top particle)
                for (let i = this.particles.length - 1; i >= 0; i--) {
                    if (this.particles[i].contains(x, y)) {
                        this.showSearchDetail(this.particles[i].searchData);
                        return;
                    }
                }
            }

            showSearchDetail(searchData) {
                document.getElementById('modalQuery').textContent = `"${searchData.query}"`;
                const latency = Math.round(searchData.latencyMs);
                document.getElementById('modalLatency').textContent = `âš¡ ${latency}ms`;

                // Display latency breakdown if available
                if (searchData.latencyBreakdown) {
                    const breakdown = searchData.latencyBreakdown;
                    const breakdownHtml = `
                        <div class="latency-breakdown">
                            <div class="latency-item">
                                <span class="label">Total Latency:</span>
                                <span class="value">${breakdown.total_ms}ms</span>
                            </div>
                            <div class="latency-item">
                                <span class="label">â”œâ”€ Embedding Generation:</span>
                                <span class="value">${breakdown.embedding_generation_ms}ms</span>
                            </div>
                            <div class="latency-item">
                                <span class="label">â”œâ”€ ChromaDB Search:</span>
                                <span class="value">${breakdown.chromadb_search_ms}ms</span>
                            </div>
                            <div class="latency-item">
                                <span class="label">â””â”€ Processing Overhead:</span>
                                <span class="value">${breakdown.processing_overhead_ms}ms</span>
                            </div>
                        </div>
                    `;
                    document.getElementById('modalLatencyBreakdown').innerHTML = breakdownHtml;
                } else {
                    document.getElementById('modalLatencyBreakdown').innerHTML = '';
                }

                const memoriesHtml = searchData.memories.map((m, index) => {
                    // Show preview (first ~300 chars) for truncated view
                    let content = m.content;
                    let preview = '';
                    let fullContent = '';
                    let isTruncated = false;

                    // Handle missing or 'None' content
                    if (!content || content === 'None' || content === null || (typeof content === 'string' && content.trim() === '')) {
                        preview = '<em>(No content available for this memory)</em>';
                        fullContent = preview;
                    } else {
                        // Store full content
                        fullContent = content;
                        
                        // Create preview (first 300 chars)
                        if (content.length > 300) {
                            preview = content.substring(0, 300) + '...';
                            isTruncated = true;
                        } else {
                            preview = content;
                        }
                    }

                    // Build tags display
                    let tagsHtml = '';
                    if (m.tags && Array.isArray(m.tags) && m.tags.length > 0) {
                        const tagElements = m.tags.map(tag => `<span class="tag">#${tag}</span>`).join('');
                        tagsHtml = `<div class="memory-tags">${tagElements}</div>`;
                    }

                    // Build topics display
                    let topicsHtml = '';
                    if (m.topics && Array.isArray(m.topics) && m.topics.length > 0) {
                        const topicElements = m.topics.map(topic => `<span class="topic">${topic}</span>`).join('');
                        topicsHtml = `<div class="memory-tags">${topicElements}</div>`;
                    }

                    // Build custom metadata display
                    let metadataHtml = '';
                    if (m.custom_metadata && Object.keys(m.custom_metadata).length > 0) {
                        const metadataStr = JSON.stringify(m.custom_metadata, null, 2);
                        metadataHtml = `<div class="metadata-section"><strong>Custom Metadata:</strong><br><pre style="margin: 4px 0 0 0; font-size: 10px;">${metadataStr}</pre></div>`;
                    }

                    // Build scores display with both query similarity and relevance
                    const queryScore = (m.query_similarity || m.score || 0).toFixed(3);
                    const relevanceScore = (m.relevance_score || 0).toFixed(3);

                    const scoresHtml = relevanceScore !== '0.000'
                        ? `<div class="memory-score">Query Match: ${queryScore} | Goal Relevance: ${relevanceScore}</div>`
                        : `<div class="memory-score">Query Match: ${queryScore}</div>`;

                    // Add Show More/Less button if content is truncated
                    const showMoreBtn = isTruncated 
                        ? `<button class="show-more-btn" data-memory-index="${index}">Show More</button>` 
                        : '';

                    return `
                        <div class="modal-memory-item">
                            ${scoresHtml}
                            <div class="memory-content ${isTruncated ? 'truncated' : ''}" data-memory-index="${index}" data-full-content="${encodeURIComponent(fullContent)}">${preview}</div>
                            ${showMoreBtn}
                            ${tagsHtml}
                            ${topicsHtml}
                            ${metadataHtml}
                        </div>
                    `;
                }).join('');

                document.getElementById('modalMemories').innerHTML = memoriesHtml;
                
                // Add event listeners for Show More/Less buttons
                document.querySelectorAll('.show-more-btn').forEach(btn => {
                    btn.addEventListener('click', function() {
                        const memoryIndex = this.getAttribute('data-memory-index');
                        const contentDiv = document.querySelector(`.memory-content[data-memory-index="${memoryIndex}"]`);
                        const fullContent = decodeURIComponent(contentDiv.getAttribute('data-full-content'));
                        
                        if (contentDiv.classList.contains('truncated')) {
                            // Expand to show full content
                            contentDiv.classList.remove('truncated');
                            contentDiv.textContent = fullContent;
                            this.textContent = 'Show Less';
                        } else {
                            // Collapse to show preview
                            const preview = fullContent.length > 300 
                                ? fullContent.substring(0, 300) + '...' 
                                : fullContent;
                            contentDiv.classList.add('truncated');
                            contentDiv.textContent = preview;
                            this.textContent = 'Show More';
                        }
                    });
                });
                
                document.getElementById('searchModal').classList.add('active');
                document.getElementById('modalOverlay').classList.add('active');
            }

            animate() {
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

                // Update and draw particles
                this.particles.forEach(particle => {
                    particle.update();
                    particle.draw(this.ctx);
                });

                requestAnimationFrame(() => this.animate());
            }
        }

        // Initialize constellation
        let constellation = null;
        document.addEventListener('DOMContentLoaded', () => {
            constellation = new Constellation('constellation-canvas');

            // Modal close handlers
            document.getElementById('modalClose').addEventListener('click', closeModal);
            document.getElementById('modalOverlay').addEventListener('click', closeModal);
        });

        function closeModal() {
            document.getElementById('searchModal').classList.remove('active');
            document.getElementById('modalOverlay').classList.remove('active');
        }
        // ========== END CONSTELLATION SYSTEM ==========

        // Load API keys from server on page load
        async function loadKeys() {
            const response = await fetch('/api/keys');
            const data = await response.json();
            OPENAI_API_KEY = data.openai_key;
            PAPR_API_KEY = data.papr_key;
            OPENAI_REALTIME_MODEL = data.openai_realtime_model || 'gpt-realtime-mini-2025-10-06';
            
            // Set WebSocket URL with model from environment
            WS_URL = `wss://api.openai.com/v1/realtime?model=${OPENAI_REALTIME_MODEL}`;
            console.log(`âœ… Using OpenAI Realtime model: ${OPENAI_REALTIME_MODEL}`);
        }

        // Load keys immediately
        loadKeys();

        // DOM elements
        const audioBtn = document.getElementById('audioBtn');
        const textInput = document.getElementById('textInput');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const errorDiv = document.getElementById('error');

        // Update status
        function setStatus(text, className) {
            status.textContent = text;
            status.className = className;
        }

        // Show error
        function showError(message) {
            errorDiv.textContent = message;
            setTimeout(() => errorDiv.textContent = '', 5000);
        }

        // Add message to transcript
        function addMessage(role, text) {
            transcript.classList.remove('hidden');
            const div = document.createElement('div');
            div.className = `message ${role}`;
            div.textContent = `${role === 'user' ? 'You' : 'AI'}: ${text}`;
            transcript.appendChild(div);
            transcript.scrollTop = transcript.scrollHeight;
        }

        // Initialize WebSocket connection
        async function connect() {
            try {
                setStatus('Connecting...', 'thinking');

                // Wait for keys to load
                if (!OPENAI_API_KEY || !PAPR_API_KEY || !WS_URL) {
                    showError('Loading API keys...');
                    setTimeout(connect, 500);
                    return;
                }

                // Connect to Realtime API using browser-compatible auth
                // Use sec-websocket-protocol for authentication
                const protocols = ['realtime', `openai-insecure-api-key.${OPENAI_API_KEY}`.substring(0, 255)];
                ws = new WebSocket(WS_URL, protocols);

                ws.onopen = () => {
                    console.log(`âœ… WebSocket connected to OpenAI Realtime API (${OPENAI_REALTIME_MODEL})`);
                    isConnected = true;

                    // Configure session (GA format)
                    console.log('ðŸ“¤ Sending session.update configuration...');
                    ws.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            type: 'realtime',
                            model: OPENAI_REALTIME_MODEL,
                            instructions: `You are PAPR's memory assistant with access to the user's personal memory database.

IMPORTANT INSTRUCTIONS:
1. When users ask about their memories, ALWAYS use the search_papr_memories tool first
2. The tool returns memory objects with these fields:
   - content: The actual memory text
   - score/relevance: How relevant to the query (higher = more relevant)
   - ID: Unique identifier you can reference
   - tags: Category tags
   - topics: Key topics
   - timestamp: When the memory was created
   - context: Additional contextual information
3. ALWAYS base your answers ONLY on the ACTUAL CONTENT from the memories returned
4. Quote or paraphrase specific details from the memory content
5. When citing memories, you can reference them by their ID for traceability
6. Pay attention to timestamps to provide temporal context (e.g., "Last month you mentioned...")
7. If no relevant memories are found, clearly say "I don't have any information about that in your memories"
8. NEVER make up or hallucinate information not present in the memory content
9. Higher scores indicate more relevant memories - prioritize those in your answer
10. If you see multiple memories about the same topic, synthesize them coherently

Format your responses conversationally, citing the relevant memories naturally with temporal context when available.`,
                            audio: {
                                input: {
                                    format: {
                                        type: 'audio/pcm',
                                        rate: 24000
                                    },
                                    turn_detection: {
                                        type: 'semantic_vad'
                                    }
                                },
                                output: {
                                    format: {
                                        type: 'audio/pcm',
                                        rate: 24000
                                    },
                                    voice: 'alloy'
                                }
                            },
                            tools: [{
                                type: 'function',
                                name: 'search_papr_memories',
                                description: 'Search the user\'s personal memory database',
                                parameters: {
                                    type: 'object',
                                    properties: {
                                        query: {
                                            type: 'string',
                                            description: 'The search query'
                                        }
                                    },
                                    required: ['query']
                                }
                            }],
                            tool_choice: 'auto'
                        }
                    }));

                    // Start audio capture
                    startAudio();
                };

                ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    console.log('ðŸ“¨ OpenAI message:', message.type, message);
                    handleServerMessage(message);
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    showError('Connection error');
                    disconnect();
                };

                ws.onclose = (event) => {
                    console.log('âŒ WebSocket closed:', {
                        code: event.code,
                        reason: event.reason,
                        wasClean: event.wasClean
                    });
                    disconnect();
                };

            } catch (error) {
                console.error('Connection error:', error);
                showError(error.message);
                setStatus('Ready', 'idle');
            }
        }

        // Handle messages from server
        function handleServerMessage(message) {
            // Don't log every single audio delta (too verbose)
            if (message.type !== 'response.output_audio.delta' && message.type !== 'input_audio_buffer.speech_started') {
                console.log('ðŸ“¬ Handling:', message.type, message);
            }

            switch (message.type) {
                case 'session.updated':
                    console.log('âœ… Session configured successfully');
                    break;

                case 'input_audio_buffer.speech_started':
                    console.log('ðŸ—£ï¸ Speech detected - user started talking');
                    break;

                case 'input_audio_buffer.speech_stopped':
                    console.log('ðŸ›‘ Speech stopped - processing...');
                    break;

                case 'conversation.item.input_audio_transcription.completed':
                    // User speech transcribed
                    const userText = message.transcript;
                    console.log('ðŸ“ Transcription:', userText);
                    if (userText) {
                        addMessage('user', userText);
                        setStatus('Thinking...', 'thinking');
                    }
                    break;

                case 'response.created':
                    // New response starting - reset audio queue
                    nextAudioTime = 0;
                    break;

                case 'response.output_audio_transcript.delta':
                    // AI is generating text response (GA event name)
                    setStatus('Speaking...', 'speaking');
                    break;

                case 'response.output_audio.delta':
                    // AI audio chunk - play it (GA event name)
                    playAudioChunk(message.delta);
                    break;

                case 'response.done':
                    // Response complete - check if it contains a function call
                    if (message.response && message.response.output) {
                        for (const item of message.response.output) {
                            if (item.type === 'function_call') {
                                handleToolCall(item);
                                return; // Don't set status to listening yet
                            }
                        }
                    }
                    setStatus('Listening...', 'listening');
                    break;

                case 'error':
                    console.error('âŒ OpenAI Error:', message.error);
                    showError(message.error.message || 'An error occurred');
                    break;

                default:
                    // Log any unhandled message types
                    if (!message.type.includes('audio.delta')) {
                        console.log('ðŸ“­ Unhandled message type:', message.type, message);
                    }
                    break;
            }
        }

        // Handle tool calls
        async function handleToolCall(item) {
            if (item.name === 'search_papr_memories') {
                setStatus('Searching memories...', 'thinking');

                const args = JSON.parse(item.arguments);
                const query = args.query;

                // Call LOCAL CoreML search endpoint!
                try {
                    const searchStartTime = performance.now();

                    const response = await fetch(PAPR_MEMORY_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            query: query,
                            max_memories: 30
                        })
                    });

                    const data = await response.json();
                    const searchLatency = Math.round(performance.now() - searchStartTime);

                    const memories = data.data.memories.map(m => ({
                        id: m.id || null,
                        content: m.content,
                        score: m.similarity_score || m.score || 0,
                        tags: m.tags || [],
                        topics: m.topics || [],
                        custom_metadata: m.custom_metadata || null,
                        metadata: m.metadata || null  // Includes timestamps, context, etc.
                    }));

                    // Add search to constellation visualization
                    if (constellation) {
                        constellation.addSearch(
                            query,
                            data.latency_ms || searchLatency,
                            memories,
                            data.latency_breakdown || null
                        );
                    }

                    // Log what we're sending to OpenAI
                    console.log(`\nðŸ“¤ Sending ${memories.length} memories to OpenAI:`);
                    const memoriesWithContent = memories.filter(m => m.content && m.content.trim()).length;
                    const memoriesWithoutContent = memories.length - memoriesWithContent;
                    console.log(`   âœ… ${memoriesWithContent} with content`);
                    console.log(`   âŒ ${memoriesWithoutContent} without content`);
                    console.log(`\nðŸ“‹ First 10 memories being sent:`);
                    memories.slice(0, 10).forEach((m, i) => {
                        const preview = m.content ? m.content.substring(0, 100) : '(No content)';
                        console.log(`   [${i + 1}] Score: ${m.similarity_score?.toFixed(4) || '0.0000'} | ${preview}...`);
                    });

                    // Format memories as clear text for better OpenAI comprehension
                    const formattedMemories = memories
                        .filter(m => m.content && m.content.trim())
                        .map((m, i) => {
                            const score = (m.score || 0).toFixed(3);
                            const memoryId = m.id ? ` [ID: ${m.id}]` : '';
                            
                            // Ensure tags and topics are arrays (defensive check)
                            const tagsArray = Array.isArray(m.tags) ? m.tags : (m.tags ? [m.tags] : []);
                            const topicsArray = Array.isArray(m.topics) ? m.topics : (m.topics ? [m.topics] : []);
                            
                            const tags = tagsArray.length > 0 ? ` [Tags: ${tagsArray.join(', ')}]` : '';
                            const topics = topicsArray.length > 0 ? ` [Topics: ${topicsArray.join(', ')}]` : '';
                            
                            // Extract timestamp if available from metadata
                            let timestamp = '';
                            if (m.metadata && m.metadata.timestamp) {
                                const date = new Date(m.metadata.timestamp);
                                timestamp = ` [Created: ${date.toLocaleDateString()}]`;
                            }
                            
                            // Extract any context info from metadata
                            let context = '';
                            if (m.metadata && m.metadata.context) {
                                context = `\nContext: ${m.metadata.context}`;
                            }
                            
                            // Format: Put topics on separate line for better visibility
                            const topicsLine = topicsArray.length > 0 ? `Topics: ${topicsArray.join(', ')}\n` : '';
                            
                            return `Memory ${i + 1} (relevance: ${score})${memoryId}${timestamp}${tags}:\n${topicsLine}${m.content}${context}\n`;
                        })
                        .join('\n---\n\n');

                    const outputText = memories.length > 0
                        ? `Found ${memories.length} relevant memories:\n\n${formattedMemories}`
                        : 'No relevant memories found for this query.';

                    // Send tool result back to OpenAI
                    ws.send(JSON.stringify({
                        type: 'conversation.item.create',
                        item: {
                            type: 'function_call_output',
                            call_id: item.call_id,
                            output: outputText
                        }
                    }));

                    // Request continuation
                    ws.send(JSON.stringify({
                        type: 'response.create'
                    }));

                } catch (error) {
                    console.error('Memory search error:', error);
                    showError('Failed to search memories');
                }
            }
        }

        // Start audio capture
        async function startAudio() {
            try {
                console.log('ðŸŽ¤ Requesting microphone access...');
                // Get microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                console.log('âœ… Microphone access granted');

                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000
                });
                console.log('âœ… AudioContext created (24kHz)');

                const source = audioContext.createMediaStreamSource(mediaStream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);

                source.connect(processor);
                processor.connect(audioContext.destination);

                let audioChunksSent = 0;
                processor.onaudioprocess = (e) => {
                    if (!ws || ws.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);

                    // Convert to PCM16
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }

                    // Send to API
                    const base64Audio = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
                    ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64Audio
                    }));

                    // Log first few audio chunks, then every 100th
                    audioChunksSent++;
                    if (audioChunksSent <= 5 || audioChunksSent % 100 === 0) {
                        console.log(`ðŸŽµ Sent audio chunk #${audioChunksSent} (${base64Audio.length} bytes)`);
                    }
                };

                setStatus('Listening...', 'listening');
                audioBtn.classList.add('active');
                console.log('âœ… Audio capture started - speak now!');

            } catch (error) {
                console.error('âŒ Audio error:', error);
                showError('Microphone access denied');
                disconnect();
            }
        }


        // Play audio chunk with proper queueing
        function playAudioChunk(base64Audio) {
            try {
                
                const audioData = atob(base64Audio);
                const bytes = new Uint8Array(audioData.length);
                for (let i = 0; i < audioData.length; i++) {
                    bytes[i] = audioData.charCodeAt(i);
                }

                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768;
                }

                const audioBuffer = audioContext.createBuffer(1, float32Array.length, 24000);
                audioBuffer.getChannelData(0).set(float32Array);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Schedule playback at the next available time
                const currentTime = audioContext.currentTime;
                const scheduleTime = Math.max(currentTime, nextAudioTime);
                source.start(scheduleTime);

                // Update next audio time
                nextAudioTime = scheduleTime + audioBuffer.duration;

            } catch (error) {
                console.error('Audio playback error:', error);
            }
        }

        // Disconnect
        function disconnect() {
            isConnected = false;

            if (ws) {
                ws.close();
                ws = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            setStatus('Ready', 'idle');
            audioBtn.classList.remove('active');
            transcript.innerHTML = '';
            transcript.classList.add('hidden');
        }

        // Audio button click handler
        audioBtn.addEventListener('click', () => {
            if (isConnected) {
                disconnect();
            } else {
                connect();
            }
        });

        // Text input Enter key handler
        textInput.addEventListener('keypress', async (e) => {
            if (e.key === 'Enter' && textInput.value.trim()) {
                const query = textInput.value.trim();
                textInput.value = '';

                // Show user query
                addMessage('user', query);
                setStatus('Searching memories...', 'thinking');

                try {
                    // Search PAPR memories with LOCAL CoreML!
                    const response = await fetch(PAPR_MEMORY_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            query: query,
                            max_memories: 30
                        })
                    });

                    const data = await response.json();
                    const memories = data.data.memories.slice(0, 5).map(m => m.content);

                    // Create AI response
                    const aiResponse = memories.length > 0
                        ? `I found ${memories.length} relevant memories:\n\n${memories.map((m, i) => `${i + 1}. ${m.substring(0, 100)}...`).join('\n\n')}`
                        : "I couldn't find any relevant memories for your query.";

                    addMessage('assistant', aiResponse);
                    setStatus('Ready', 'idle');

                } catch (error) {
                    console.error('Search error:', error);
                    showError('Failed to search memories');
                    setStatus('Ready', 'idle');
                }
            }
        });
    </script>
</body>
</html>
